{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of9Zo8IG6acm"
   },
   "source": [
    "\n",
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1695980001182,
     "user": {
      "displayName": "Joie Lim",
      "userId": "08814076690383135501"
     },
     "user_tz": -480
    },
    "id": "OQ5-Jyps6acj",
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4824,
     "status": "ok",
     "timestamp": 1695980028233,
     "user": {
      "displayName": "Joie Lim",
      "userId": "08814076690383135501"
     },
     "user_tz": -480
    },
    "id": "f-UiUy8B6aco",
    "outputId": "d02b4ca5-b50e-42c3-91d5-83c635347fe2",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from datetime import date\n",
    "from pvlib.iotools import read_epw\n",
    "\n",
    "from pykrige.rk import RegressionKriging\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1695980036519,
     "user": {
      "displayName": "Joie Lim",
      "userId": "08814076690383135501"
     },
     "user_tz": -480
    },
    "id": "Ds8JsapSAH8r"
   },
   "outputs": [],
   "source": [
    "#dir = 'C:\\\\GitHub\\\\microclimate-dl-predict\\\\data\\\\'\n",
    "dir = \"C:\\\\Users\\\\pkastner\\\\Documents\\\\GitHub\\\\microclimate-dl-predict\\\\data\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUmUksbS8guq"
   },
   "source": [
    "\n",
    "# Load, verify and process input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurenames={\"RH0719\":'RH',\"Tem0719\":'Temperature'}\n",
    "measureunit={\"Tem0719\":'Â°C',\"RH0719\":'%'}\n",
    "measure = \"RH0719\"\n",
    "#measure = \"Tem0719\"\n",
    "testmeasure = \"RH0819\"\n",
    "#testmeasure = \"Tem0819\"\n",
    "df = pd.read_csv(dir + measure +'.csv')\n",
    "testdf = pd.read_csv(dir + testmeasure +'.csv')\n",
    "\n",
    "\n",
    "# df = df.drop(df.index[2])\n",
    "\n",
    "amy,meta=read_epw(dir+'SGP_Singapore.486980_IWEC.epw')\n",
    "changi,meta=read_epw(dir+'SGP_SINGAPORE-CHANGI-AP_486980S_19.epw')\n",
    "if measure == \"Tem0719\":\n",
    "    mykey='temp_air'\n",
    "else:\n",
    "    mykey='relative_humidity'\n",
    "changidata=changi.loc[(changi['year'].astype('str')+changi['month'].astype('str')=='20197'),[mykey]]\n",
    "amydata=amy.loc[(amy['month'].astype('str')=='7'),[mykey]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windspeeddf = pd.read_csv(dir + 'ws0719.csv')\n",
    "solardf = pd.read_csv(dir + 'sr0719.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 866
    },
    "executionInfo": {
     "elapsed": 3796,
     "status": "ok",
     "timestamp": 1695984815898,
     "user": {
      "displayName": "Joie Lim",
      "userId": "08814076690383135501"
     },
     "user_tz": -480
    },
    "id": "VFAhPxd66acp",
    "outputId": "c1bba5e9-e61b-4e12-cc2e-ba12c0122285"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkastner\\AppData\\Local\\Temp\\ipykernel_65304\\1863566996.py:1: DtypeWarning: Columns (10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  griddf = pd.read_csv(dir + '1m_GridPoints_distTo_and_zones_3414.csv').fillna(0)\n",
      "C:\\Users\\pkastner\\AppData\\Local\\Temp\\ipykernel_65304\\1863566996.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  t = t.replace(\"Vegetated Ridge\", 1)\n",
      "C:\\Users\\pkastner\\AppData\\Local\\Temp\\ipykernel_65304\\1863566996.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  griddf['distToTree'].loc[griddf['VegetatedRidge'] == 1] = 0.0\n",
      "C:\\Users\\pkastner\\AppData\\Local\\Temp\\ipykernel_65304\\1863566996.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  griddf['distToTree'].loc[griddf['VegetatedRidge'] == 1] = 0.0\n",
      "C:\\Users\\pkastner\\AppData\\Local\\Temp\\ipykernel_65304\\1863566996.py:16: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  t = t.replace(\"Temparea\", 1)\n",
      "C:\\Users\\pkastner\\AppData\\Local\\Temp\\ipykernel_65304\\1863566996.py:17: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  t = t.replace(\"Vegetated Ridge\", 1)\n",
      "C:\\Users\\pkastner\\AppData\\Local\\Temp\\ipykernel_65304\\1863566996.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  t = t.replace(\"Valley\", 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>ID</th>\n",
       "      <th>distToBuilding</th>\n",
       "      <th>percentbuilt</th>\n",
       "      <th>terrain</th>\n",
       "      <th>Area</th>\n",
       "      <th>Temparea</th>\n",
       "      <th>Valley</th>\n",
       "      <th>distToTree</th>\n",
       "      <th>...</th>\n",
       "      <th>percentroad</th>\n",
       "      <th>percentpath</th>\n",
       "      <th>percentwalkway</th>\n",
       "      <th>percentcourttrack</th>\n",
       "      <th>percentcarpark</th>\n",
       "      <th>numtrees</th>\n",
       "      <th>Zone 1</th>\n",
       "      <th>Zone 2</th>\n",
       "      <th>Zone 3</th>\n",
       "      <th>Zone 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21310.45279</td>\n",
       "      <td>31360.82993</td>\n",
       "      <td>2</td>\n",
       "      <td>1.57015</td>\n",
       "      <td>17.48721</td>\n",
       "      <td>25.03599</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>14.85820</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21042.23831</td>\n",
       "      <td>31242.52129</td>\n",
       "      <td>3</td>\n",
       "      <td>0.68151</td>\n",
       "      <td>37.08572</td>\n",
       "      <td>47.24897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00043</td>\n",
       "      <td>...</td>\n",
       "      <td>32.90080</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21251.46471</td>\n",
       "      <td>31202.70922</td>\n",
       "      <td>4</td>\n",
       "      <td>5.49422</td>\n",
       "      <td>45.78975</td>\n",
       "      <td>42.84434</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>32.10427</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21210.28151</td>\n",
       "      <td>30976.03165</td>\n",
       "      <td>6</td>\n",
       "      <td>2.84506</td>\n",
       "      <td>39.82353</td>\n",
       "      <td>40.05906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>...</td>\n",
       "      <td>28.49887</td>\n",
       "      <td>26.57608</td>\n",
       "      <td>6.61014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20933.16250</td>\n",
       "      <td>30824.55084</td>\n",
       "      <td>7</td>\n",
       "      <td>9.90256</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>18.97783</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21188.01955</td>\n",
       "      <td>30822.33307</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>55.52813</td>\n",
       "      <td>47.79486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21254.80024</td>\n",
       "      <td>31068.91350</td>\n",
       "      <td>11</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.38553</td>\n",
       "      <td>47.58942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>2.45925</td>\n",
       "      <td>1.77000</td>\n",
       "      <td>15.15244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.41425</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21908.06866</td>\n",
       "      <td>30561.35985</td>\n",
       "      <td>12</td>\n",
       "      <td>10.52352</td>\n",
       "      <td>15.75304</td>\n",
       "      <td>33.60504</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22150.68034</td>\n",
       "      <td>30388.85790</td>\n",
       "      <td>13</td>\n",
       "      <td>19.30173</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>35.78543</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>...</td>\n",
       "      <td>73.29213</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.47421</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22196.31786</td>\n",
       "      <td>30779.18631</td>\n",
       "      <td>16</td>\n",
       "      <td>21.65002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>41.24351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>97.22544</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22082.80548</td>\n",
       "      <td>31005.86720</td>\n",
       "      <td>17</td>\n",
       "      <td>5.48086</td>\n",
       "      <td>43.73862</td>\n",
       "      <td>23.54144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>...</td>\n",
       "      <td>28.40658</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.13630</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21843.53252</td>\n",
       "      <td>31150.72544</td>\n",
       "      <td>18</td>\n",
       "      <td>38.93108</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>22.02973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>...</td>\n",
       "      <td>29.41022</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>35.785</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21546.39146</td>\n",
       "      <td>31428.27511</td>\n",
       "      <td>19</td>\n",
       "      <td>24.41229</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>21.24668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>...</td>\n",
       "      <td>25.12530</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02837</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21147.97437</td>\n",
       "      <td>31630.63663</td>\n",
       "      <td>20</td>\n",
       "      <td>17.67098</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>23.56321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>...</td>\n",
       "      <td>40.36483</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows Ã 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              X            Y  ID  distToBuilding  percentbuilt   terrain  \\\n",
       "0   21310.45279  31360.82993   2         1.57015      17.48721  25.03599   \n",
       "1   21042.23831  31242.52129   3         0.68151      37.08572  47.24897   \n",
       "2   21251.46471  31202.70922   4         5.49422      45.78975  42.84434   \n",
       "3   21210.28151  30976.03165   6         2.84506      39.82353  40.05906   \n",
       "4   20933.16250  30824.55084   7         9.90256       0.00000  18.97783   \n",
       "5   21188.01955  30822.33307   8         0.00000      55.52813  47.79486   \n",
       "6   21254.80024  31068.91350  11         0.00000       9.38553  47.58942   \n",
       "7   21908.06866  30561.35985  12        10.52352      15.75304  33.60504   \n",
       "8   22150.68034  30388.85790  13        19.30173       0.00000  35.78543   \n",
       "9   22196.31786  30779.18631  16        21.65002       0.00000  41.24351   \n",
       "10  22082.80548  31005.86720  17         5.48086      43.73862  23.54144   \n",
       "11  21843.53252  31150.72544  18        38.93108       0.00000  22.02973   \n",
       "12  21546.39146  31428.27511  19        24.41229       0.00000  21.24668   \n",
       "13  21147.97437  31630.63663  20        17.67098       0.00000  23.56321   \n",
       "\n",
       "    Area  Temparea  Valley  distToTree  ...  percentroad  percentpath  \\\n",
       "0      0         1       1     0.00008  ...      0.00000     14.85820   \n",
       "1      0         0       1     0.00043  ...     32.90080      0.00000   \n",
       "2      0         0       1     0.00005  ...      0.00000     32.10427   \n",
       "3      0         0       0     0.00008  ...     28.49887     26.57608   \n",
       "4      0         0       0     0.00002  ...      0.00000      0.00000   \n",
       "5      0         0       1     0.00007  ...      0.00000      0.00000   \n",
       "6      0         0       1     0.00005  ...      2.45925      1.77000   \n",
       "7      1         0       0     0.00015  ...      0.00000      0.00000   \n",
       "8      0         1       0     0.00019  ...     73.29213      0.00000   \n",
       "9      0         0       0     0.00007  ...      0.00000      0.00000   \n",
       "10     0         0       0     0.00002  ...     28.40658      0.00000   \n",
       "11     0         0       0     0.00018  ...     29.41022      0.00000   \n",
       "12     0         0       0     0.00015  ...     25.12530      0.00000   \n",
       "13     0         0       0     0.00004  ...     40.36483      0.00000   \n",
       "\n",
       "    percentwalkway  percentcourttrack  percentcarpark  numtrees  Zone 1  \\\n",
       "0          0.00000              0.000         0.00000         0    True   \n",
       "1          0.00000              0.000         0.00000         0    True   \n",
       "2          0.00000              0.000         0.00000         0    True   \n",
       "3          6.61014              0.000         0.00000         0   False   \n",
       "4          0.00000              0.000         0.00000         1   False   \n",
       "5          0.00000              0.000         0.00000         1   False   \n",
       "6         15.15244              0.000        22.41425         3    True   \n",
       "7          0.00000              0.000         0.00000         0   False   \n",
       "8          1.47421              0.000         0.00000         0   False   \n",
       "9          0.00000              0.000        97.22544         1   False   \n",
       "10         0.00000              0.000         0.13630         1   False   \n",
       "11         0.00000             35.785         0.00000         0   False   \n",
       "12         0.02837              0.000         0.00000         0   False   \n",
       "13         0.00000              0.000         0.00000         2   False   \n",
       "\n",
       "    Zone 2  Zone 3  Zone 4  \n",
       "0    False   False   False  \n",
       "1    False   False   False  \n",
       "2    False   False   False  \n",
       "3     True   False   False  \n",
       "4    False   False    True  \n",
       "5    False   False    True  \n",
       "6    False   False   False  \n",
       "7     True   False   False  \n",
       "8     True   False   False  \n",
       "9    False    True   False  \n",
       "10   False    True   False  \n",
       "11    True   False   False  \n",
       "12    True   False   False  \n",
       "13    True   False   False  \n",
       "\n",
       "[14 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>distToBuilding</th>\n",
       "      <th>distToCarpark</th>\n",
       "      <th>distToCourtTrack</th>\n",
       "      <th>distToPath</th>\n",
       "      <th>distToRoad</th>\n",
       "      <th>distToWalkway</th>\n",
       "      <th>distToTree</th>\n",
       "      <th>LOTKEY</th>\n",
       "      <th>VegetatedRidge</th>\n",
       "      <th>TempArea</th>\n",
       "      <th>terrain</th>\n",
       "      <th>0</th>\n",
       "      <th>Zone 1</th>\n",
       "      <th>Zone 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21211.76</td>\n",
       "      <td>31449.25</td>\n",
       "      <td>35.13702</td>\n",
       "      <td>40.96888</td>\n",
       "      <td>5.76221</td>\n",
       "      <td>32.17034</td>\n",
       "      <td>22.79395</td>\n",
       "      <td>21.34219</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>MK03-05112L</td>\n",
       "      <td>0</td>\n",
       "      <td>TempArea</td>\n",
       "      <td>24.44757</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21211.76</td>\n",
       "      <td>31448.25</td>\n",
       "      <td>34.28551</td>\n",
       "      <td>40.84101</td>\n",
       "      <td>6.46347</td>\n",
       "      <td>31.29244</td>\n",
       "      <td>22.37293</td>\n",
       "      <td>20.91852</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>MK03-05112L</td>\n",
       "      <td>0</td>\n",
       "      <td>TempArea</td>\n",
       "      <td>25.59470</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21211.76</td>\n",
       "      <td>31447.25</td>\n",
       "      <td>33.44222</td>\n",
       "      <td>40.73729</td>\n",
       "      <td>6.01520</td>\n",
       "      <td>30.41453</td>\n",
       "      <td>21.95191</td>\n",
       "      <td>20.49564</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>MK03-05112L</td>\n",
       "      <td>0</td>\n",
       "      <td>TempArea</td>\n",
       "      <td>25.59470</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21211.76</td>\n",
       "      <td>31446.25</td>\n",
       "      <td>32.60780</td>\n",
       "      <td>40.64762</td>\n",
       "      <td>5.70867</td>\n",
       "      <td>29.53662</td>\n",
       "      <td>21.53089</td>\n",
       "      <td>20.07277</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>MK03-05112L</td>\n",
       "      <td>0</td>\n",
       "      <td>TempArea</td>\n",
       "      <td>25.59470</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21211.76</td>\n",
       "      <td>31445.25</td>\n",
       "      <td>31.78293</td>\n",
       "      <td>40.55804</td>\n",
       "      <td>5.56732</td>\n",
       "      <td>28.66267</td>\n",
       "      <td>21.10987</td>\n",
       "      <td>19.64989</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>MK03-05112L</td>\n",
       "      <td>0</td>\n",
       "      <td>TempArea</td>\n",
       "      <td>25.59470</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y  distToBuilding  distToCarpark  distToCourtTrack  \\\n",
       "0  21211.76  31449.25        35.13702       40.96888           5.76221   \n",
       "1  21211.76  31448.25        34.28551       40.84101           6.46347   \n",
       "2  21211.76  31447.25        33.44222       40.73729           6.01520   \n",
       "3  21211.76  31446.25        32.60780       40.64762           5.70867   \n",
       "4  21211.76  31445.25        31.78293       40.55804           5.56732   \n",
       "\n",
       "   distToPath  distToRoad  distToWalkway  distToTree       LOTKEY  \\\n",
       "0    32.17034    22.79395       21.34219     0.00009  MK03-05112L   \n",
       "1    31.29244    22.37293       20.91852     0.00008  MK03-05112L   \n",
       "2    30.41453    21.95191       20.49564     0.00007  MK03-05112L   \n",
       "3    29.53662    21.53089       20.07277     0.00006  MK03-05112L   \n",
       "4    28.66267    21.10987       19.64989     0.00006  MK03-05112L   \n",
       "\n",
       "   VegetatedRidge  TempArea   terrain      0  Zone 1  Zone 3  \n",
       "0               0  TempArea  24.44757  False    True   False  \n",
       "1               0  TempArea  25.59470  False    True   False  \n",
       "2               0  TempArea  25.59470  False    True   False  \n",
       "3               0  TempArea  25.59470  False    True   False  \n",
       "4               0  TempArea  25.59470  False    True   False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "griddf = pd.read_csv(dir + '1m_GridPoints_distTo_and_zones_3414.csv').fillna(0)\n",
    "wsdf = pd.read_csv(dir + 'WSPoints_TreesAndStreets_3414.csv').fillna(0)\n",
    "t = pd.concat([griddf, pd.get_dummies(griddf.HorticultureZone)], axis=1)\n",
    "t = t.replace(\"Temparea\", 1)\n",
    "t = t.replace(\"Vegetated Ridge\", 1)\n",
    "# t = t.replace(\"Valley\", 1)\n",
    "# t = t.rename(columns={\"Area\": \"VegetatedRidge\"})\n",
    "### drop features that share high correlation with other features (not useful for prediction)\n",
    "griddf = t.drop(['id','HorticultureZone'], axis=1)\n",
    "# griddf = t.drop(['id','HorticultureZone','gridarea','buildingfootprintarea','roadarea','patharea','walkwayarea','courttrackarea','carparkarea'], axis=1)\n",
    "### set points within VegetatedRidge to have distToTree 0.0 (trees within the area are not doccumented but the area is densely forrested)\n",
    "### helps a bit to make distToTree useful but numtrees is still inaccurate for this area\n",
    "griddf['distToTree'].loc[griddf['VegetatedRidge'] == 1] = 0.0\n",
    "\n",
    "t = pd.concat([wsdf, pd.get_dummies(wsdf.HorticultureZone)], axis=1)\n",
    "t = t.replace(\"Temparea\", 1)\n",
    "t = t.replace(\"Vegetated Ridge\", 1)\n",
    "t = t.replace(\"Valley\", 1)\n",
    "# t = t.rename(columns={\"Area\": \"VegetatedRidge\"})\n",
    "t = t.sort_values(by=['ID'])\n",
    "### drop features that share high correlation with other features (not useful for prediction)\n",
    "wsdf = t.drop(['Lat','Long','HorticultureZone','Location','Type','Description','gridarea','buildingfootprintarea','roadarea','patharea','walkwayarea','courttrackarea','carparkarea'], axis=1)\n",
    "wsdf = wsdf.reset_index(drop=True)\n",
    "\n",
    "plotdf = testdf.transpose().iloc[2:16,:]\n",
    "plotdf['X']=list(wsdf['X'])\n",
    "plotdf['Y']=list(wsdf['Y'])\n",
    "\n",
    "display(wsdf)\n",
    "display(griddf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZf8juVc85Hy"
   },
   "source": [
    "# Regression kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allstations=np.array(range(14))\n",
    "targetstationid=7\n",
    "otherstationsid=np.delete(allstations,targetstationid).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "percentfeatures=['percentroad','percentpath','percentwalkway','percentcourttrack','percentcarpark']\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, embedding_length, hidden_size,output_size,batch_size):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        super(MyModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(embedding_length, hidden_size,batch_first=True)\n",
    "        self.label = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, input):\n",
    "        h_0 = Variable(torch.zeros(1,self.batch_size, self.hidden_size))\n",
    "        c_0 = Variable(torch.zeros(1,self.batch_size, self.hidden_size))\n",
    "        output, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0))\n",
    "        return self.label(final_hidden_state[-1]) \n",
    "class gru(nn.Module):\n",
    "    def __init__(self, embedding_length, hidden_size,output_size,batch_size):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        super(gru, self).__init__()\n",
    "        self.lstm = nn.GRU(embedding_length, hidden_size,batch_first=True)\n",
    "        self.label = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, input):\n",
    "        h_0 = Variable(torch.zeros(1,self.batch_size, self.hidden_size))\n",
    "        \n",
    "        output, final_hidden_state = self.lstm(input, h_0)\n",
    "        return self.label(final_hidden_state[-1]) \n",
    "\n",
    "embedding_length=15\n",
    "batchsize=16\n",
    "mymodel=gru(embedding_length=embedding_length,hidden_size=64,output_size=13,batch_size=batchsize)\n",
    "optimizer = torch.optim.SGD(mymodel.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "def train_model(model, train_iter, epoch):\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        loss=0\n",
    "        optimizer.zero_grad()\n",
    "        for idx, batch in enumerate(train_iter):\n",
    "            prediction = model(batch.x)\n",
    "            loss = loss + torch.norm(prediction-batch.y,\"fro\")\n",
    "        loss=loss/(idx+1)\n",
    "        print(\"epoch {}: Training Loss normalized Root MSE : {} %\".format(e,np.sqrt(loss.detach().numpy())) )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if loss <0.1:\n",
    "            break\n",
    "    return loss\n",
    "\n",
    "class Mydata():\n",
    "    def __init__(self,x,y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "\n",
    "measure='Tem0719'\n",
    "npdata=np.array(pd.read_csv(dir + measure +'.csv').iloc[:,2:16])\n",
    "hourdata=np.sum(npdata.reshape([-1,60,14]),axis=1)/60\n",
    "testhourdata=np.sum(np.array(testdf.iloc[:,2:16]).reshape([-1,60,14]),axis=1)/60\n",
    "mean = hourdata.mean()\n",
    "std = hourdata.std()\n",
    "pdhourdata=pd.DataFrame(hourdata).transpose()\n",
    "pdhourdata['X']=list(wsdf['X'])\n",
    "pdhourdata['Y']=list(wsdf['Y'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'months' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m griddflist\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     30\u001b[0m plotdflist\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, mth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mmonths\u001b[49m):\n\u001b[0;32m     32\u001b[0m     griddflist\u001b[38;5;241m.\u001b[39mappend(griddf\u001b[38;5;241m.\u001b[39mcopy())\n\u001b[0;32m     33\u001b[0m     plotdflist\u001b[38;5;241m.\u001b[39mappend(plotdf\u001b[38;5;241m.\u001b[39mcopy())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'months' is not defined"
     ]
    }
   ],
   "source": [
    "measure='Tem0719'\n",
    "npdata=np.array(pd.read_csv(dir + measure +'.csv').iloc[:,2:16])\n",
    "hourdata=np.sum(npdata.reshape([-1,60,14]),axis=1)/60\n",
    "testhourdata=np.sum(np.array(testdf.iloc[:,2:16]).reshape([-1,60,14]),axis=1)/60\n",
    "mean = hourdata.mean()\n",
    "std = hourdata.std()\n",
    "\n",
    "data=[]\n",
    "testdata=[]\n",
    "allstations=np.array(range(14))\n",
    "targetstationid=7\n",
    "otherstationsid=np.delete(allstations,targetstationid).tolist()\n",
    "with open('trainednw\\\\{}lstmmodel_target{}.pkl'.format(measure,targetstationid), 'rb') as f:\n",
    "        mymodel = pickle.load(f)\n",
    "if batchsize ==1:\n",
    "    for i in range(0,hourdata.shape[0]-embedding_length-batchsize,batchsize):\n",
    "        data.append(Mydata(torch.tensor((np.delete(hourdata[i:i+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32).transpose(0,1),torch.tensor((np.delete(hourdata[i+embedding_length:i+1+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32)))\n",
    "    for i in range(0,testhourdata.shape[0]-embedding_length-batchsize,batchsize):\n",
    "        testdata.append(Mydata(torch.tensor((np.delete(testhourdata[i:i+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32).transpose(0,1),torch.tensor((np.delete(testhourdata[i+embedding_length:i+1+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32)))\n",
    "\n",
    "else:\n",
    "    for i in range(0,hourdata.shape[0]-embedding_length-batchsize,batchsize):\n",
    "        data.append(Mydata(torch.tensor(np.array([(np.delete(hourdata[i+k:i+k+embedding_length,:],targetstationid,axis=1)-mean)/std for k in range(batchsize)]),dtype=torch.float32).transpose(1,2)\n",
    "                    ,torch.tensor((np.delete(hourdata[i+embedding_length:i+batchsize+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32)))\n",
    "    for i in range(0,testhourdata.shape[0]-embedding_length-batchsize,batchsize):\n",
    "        testdata.append(Mydata(torch.tensor(np.array([(np.delete(testhourdata[i+k:i+k+embedding_length,:],targetstationid,axis=1)-mean)/std for k in range(batchsize)]),dtype=torch.float32).transpose(1,2)\n",
    "                    ,torch.tensor((np.delete(testhourdata[i+embedding_length:i+batchsize+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32)))\n",
    "\n",
    "griddflist=[]\n",
    "plotdflist=[]\n",
    "for i, mth in enumerate(months):\n",
    "    griddflist.append(griddf.copy())\n",
    "    plotdflist.append(plotdf.copy())\n",
    "    print(\"Date : {}, Time : {}\".format(df.iloc[(mth*batchsize+batchindex+embedding_length)*60,0],df.iloc[(mth*batchsize+batchindex+embedding_length)*60,1]))\n",
    "\n",
    "    x = np.array(list(zip(wsdf.drop(targetstationid).X, wsdf.drop(targetstationid).Y)))\n",
    "    truevalue = hourdata[mth*batchsize+batchindex+embedding_length,:]\n",
    "    lastdayvalue = hourdata[mth*batchsize+batchindex+embedding_length-24,:]\n",
    "    target = mymodel(data[mth].x)[batchindex,:].detach().numpy()*std+mean\n",
    "    # p_train, p_test, x_train, x_test, target_train, target_test = train_test_split(\n",
    "    #     p, x, target, test_size=0.3, random_state=42\n",
    "    # )\n",
    "    plotdf['plotdata']=truevalue\n",
    "    print(\"=\" * 40)\n",
    "    m_ok = OrdinaryKriging(x[:,0],x[:,1],target,variogram_model=k,verbose=False)\n",
    "    m_rk = RegressionKriging(regression_model=model, n_closest_points=n, variogram_model=k, verbose=False)\n",
    "\n",
    "    # m_rk.fit(p_train, x_train,target_train)\n",
    "    # score = m_rk.score(p_test, x_test,target_test)\n",
    "    # scores_mths.append(score)\n",
    "\n",
    "    m_rk.fit(p, x, target)\n",
    "    result = m_rk.predict(target_p, target_x)\n",
    "    griddflist[i][measure+'_lstmrk_'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=[]\n",
    "for k in variogram_models:\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\n",
    "    for mth in range(len(data)):\n",
    "        for batchindex in range(batchsize):\n",
    "            truevalue = hourdata[mth*batchsize+batchindex+embedding_length,targetstationid]\n",
    "            target = mymodel(data[mth].x)[batchindex,:].detach().numpy()*std+mean\n",
    "            m_rk = RegressionKriging(regression_model=model, n_closest_points=n, variogram_model=k, verbose=False)\n",
    "            m_rk.fit(p, x, target)\n",
    "            result = m_rk.predict(target_p, target_x)\n",
    "            plotdf.iloc[[targetstationid],embedding_length+mth*batchsize+batchindex]=(result-truevalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select features for model, excluded most of the percent** because they seem quite small and not significant, especially for features with small area like walkways\n",
    "features = ['terrain','distToBuilding','distToTree','distToWalkway','distToRoad','distToPath','distToCourtTrack','distToCarpark']\n",
    "p = wsdf[features].drop(targetstationid)\n",
    "target_p = wsdf.loc[targetstationid,features].to_numpy().reshape(1,-1)\n",
    "target_x = np.array([(wsdf.loc[targetstationid,'X'],wsdf.loc[targetstationid,'Y'])]).reshape(1,-1)\n",
    "\n",
    "feature_importance_df = pd.DataFrame(features, columns =['FeatureName'])\n",
    "\n",
    "## prepare data for training and models to train\n",
    "data=[]\n",
    "testdata=[]\n",
    "if batchsize ==1:\n",
    "    for i in range(0,hourdata.shape[0]-embedding_length-batchsize,batchsize):\n",
    "        data.append(Mydata(torch.tensor((np.delete(hourdata[i:i+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32).transpose(0,1),torch.tensor((np.delete(hourdata[i+embedding_length:i+1+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32)))\n",
    "    for i in range(0,testhourdata.shape[0]-embedding_length-batchsize,batchsize):\n",
    "        testdata.append(Mydata(torch.tensor((np.delete(testhourdata[i:i+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32).transpose(0,1),torch.tensor((np.delete(testhourdata[i+embedding_length:i+1+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32)))\n",
    "\n",
    "else:\n",
    "    for i in range(0,hourdata.shape[0]-embedding_length-batchsize,batchsize):\n",
    "        data.append(Mydata(torch.tensor(np.array([(np.delete(hourdata[i+k:i+k+embedding_length,:],targetstationid,axis=1)-mean)/std for k in range(batchsize)]),dtype=torch.float32).transpose(1,2)\n",
    "                    ,torch.tensor((np.delete(hourdata[i+embedding_length:i+batchsize+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32)))\n",
    "    for i in range(0,testhourdata.shape[0]-embedding_length-batchsize,batchsize):\n",
    "        testdata.append(Mydata(torch.tensor(np.array([(np.delete(testhourdata[i+k:i+k+embedding_length,:],targetstationid,axis=1)-mean)/std for k in range(batchsize)]),dtype=torch.float32).transpose(1,2)\n",
    "                    ,torch.tensor((np.delete(testhourdata[i+embedding_length:i+batchsize+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32)))\n",
    "\n",
    "\n",
    "methods=['_lstmrk_','_lstmok_','_grurk_','_gruok_','_ne_','_iwec_','_changi_']#'\n",
    "puredata={}\n",
    "for method in methods:\n",
    "    puredata[measure+method]=plotdf.iloc[:,embedding_length:embedding_length+len(data)*batchsize].to_numpy()\n",
    "### SVR model parameters\n",
    "C = 0.0005\n",
    "gamma = 5\n",
    "kernel = ['linear'] # options: ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "### RandomForestRegressor parameters\n",
    "n_estimators=50\n",
    "random_state=4\n",
    "\n",
    "### RegressionKrigging parameters\n",
    "n = 8\n",
    "variogram_models = ['spherical'] # options: [\"linear\", \"power\", \"gaussian\", \"spherical\", \"exponential\"]\n",
    "\n",
    "#months = [\"Feb-19\",\"Mar-19\",\"Apr-19\",\"May-19\",\"Jun-19\",\"Jul-19\",\"Aug-19\",\"Sep-19\",\"Oct-19\",\"Nov-19\",\"Dec-19\",\"Jan-20\",\"Feb-20\",\"Mar-20\",\"Apr-20\"]\n",
    "months = [12,31,5]\n",
    "#months = [21]\n",
    "batchindex = 5\n",
    "### Load base geojson grid to export geojson file\n",
    "basejson = []\n",
    "# with open(dir + 'GeoJSON/BaseGrid.geojson', 'r') as file:\n",
    "#     basejson = json.load(file)\n",
    "dt=[]\n",
    "for i, mth in enumerate(months):\n",
    "    dt.append(\"Date : {}, Time : {}\".format(df.iloc[(mth*batchsize+batchindex+embedding_length)*60,0],df.iloc[(mth*batchsize+batchindex+embedding_length)*60,1]))\n",
    "    plotdf[measure+'_rk_'+dt[i]]=0\n",
    "    plotdf[measure+'_ok_'+dt[i]]=0\n",
    "    plotdf[measure+'_ne_'+dt[i]]=0\n",
    "for targetstationid in range(14):    \n",
    "    allstations=np.array(range(14))\n",
    "    otherstationsid=np.delete(allstations,targetstationid).tolist()\n",
    "    import pickle\n",
    "    data=[]\n",
    "    testdata=[]\n",
    "    if batchsize ==1:\n",
    "        for i in range(0,hourdata.shape[0]-embedding_length-batchsize,batchsize):\n",
    "            data.append(Mydata(torch.tensor((np.delete(hourdata[i:i+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32).transpose(0,1),torch.tensor((np.delete(hourdata[i+embedding_length:i+1+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32)))\n",
    "        for i in range(0,testhourdata.shape[0]-embedding_length-batchsize,batchsize):\n",
    "            testdata.append(Mydata(torch.tensor((np.delete(testhourdata[i:i+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32).transpose(0,1),torch.tensor((np.delete(testhourdata[i+embedding_length:i+1+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32)))\n",
    "\n",
    "    else:\n",
    "        for i in range(0,hourdata.shape[0]-embedding_length-batchsize,batchsize):\n",
    "            data.append(Mydata(torch.tensor(np.array([(np.delete(hourdata[i+k:i+k+embedding_length,:],targetstationid,axis=1)-mean)/std for k in range(batchsize)]),dtype=torch.float32).transpose(1,2)\n",
    "                        ,torch.tensor((np.delete(hourdata[i+embedding_length:i+batchsize+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32)))\n",
    "        for i in range(0,testhourdata.shape[0]-embedding_length-batchsize,batchsize):\n",
    "            testdata.append(Mydata(torch.tensor(np.array([(np.delete(testhourdata[i+k:i+k+embedding_length,:],targetstationid,axis=1)-mean)/std for k in range(batchsize)]),dtype=torch.float32).transpose(1,2)\n",
    "                        ,torch.tensor((np.delete(testhourdata[i+embedding_length:i+batchsize+embedding_length,:],targetstationid,axis=1)-mean)/std,dtype=torch.float32)))\n",
    "\n",
    "    with open('TEMmodel_target{}.pkl'.format(targetstationid), 'rb') as f:\n",
    "        mymodel = pickle.load(f)\n",
    "    #mymodel=MyModel(embedding_length=embedding_length,hidden_size=64,output_size=13,batch_size=batchsize)\n",
    "    train_model(mymodel, data, epoch=1000)\n",
    "    with open('TEMmodel_target{}.pkl'.format(targetstationid),'wb') as f:\n",
    "        pickle.dump(mymodel,f)\n",
    "    #mymodel=clf2\n",
    "    \n",
    "\n",
    "    for k in variogram_models:\n",
    "        # print(k)\n",
    "        # model = SVR(C=C, gamma=gamma, kernel=k)\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\n",
    "        # model = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "\n",
    "        scores_mths = []\n",
    "        #\n",
    "        #   continue\n",
    "        \n",
    "        for i, mth in enumerate(months):\n",
    "            \n",
    "            x = np.array(list(zip(wsdf.drop(targetstationid).X, wsdf.drop(targetstationid).Y)))\n",
    "            truevalue = hourdata[mth*batchsize+batchindex+embedding_length,:]\n",
    "            target = mymodel(data[mth].x)[batchindex,:].detach().numpy()*std+mean\n",
    "            # p_train, p_test, x_train, x_test, target_train, target_test = train_test_split(\n",
    "            #     p, x, target, test_size=0.3, random_state=42\n",
    "            # )\n",
    "            print(\"=\" * 40)\n",
    "            m_ok = OrdinaryKriging(x[:,0],x[:,1],target,variogram_model=k,verbose=False)\n",
    "            m_rk = RegressionKriging(regression_model=model, n_closest_points=n, variogram_model=k, verbose=False)\n",
    "\n",
    "            # m_rk.fit(p_train, x_train,target_train)\n",
    "            # score = m_rk.score(p_test, x_test,target_test)\n",
    "            # scores_mths.append(score)\n",
    "\n",
    "            m_rk.fit(p, x, target)\n",
    "            result = m_rk.predict(target_p, target_x)\n",
    "            plotdf.loc[:,measure+'_rk_'+dt[i]].iloc[[targetstationid]] = result[0]-truevalue[targetstationid]\n",
    "            z,sigma=m_ok.execute('points',target_x[0,0],target_x[0,1])\n",
    "            plotdf.loc[:,measure+'_ok_'+dt[i]].iloc[[targetstationid]] = z[0]-truevalue[targetstationid]\n",
    "            plotdf.loc[:,measure+'_ne_'+dt[i]].iloc[[targetstationid]] = truevalue[otherstationsid[np.argmin((wsdf.loc[otherstationsid,'X']-wsdf.loc[targetstationid,'X'])**2+(wsdf.loc[otherstationsid,'Y']-wsdf.loc[targetstationid,'Y'])**2)]]-truevalue[targetstationid]\n",
    "            \n",
    "for i, mth in enumerate(months):\n",
    "    print(dt[i])        \n",
    "    for method in methods:\n",
    "        g = sns.scatterplot(x=\"X\", y=\"Y\",\n",
    "                        hue=measure+method+dt[i],\n",
    "                        palette=\"Spectral_r\",\n",
    "                        data=plotdf.iloc[otherstationsid,:],\n",
    "                        #hue_norm=(-1,1),\n",
    "                        edgecolor=\"black\")\n",
    "        plt.title(\"Temperature prediction error samples, Date : {}, Time : {}\".format(df.iloc[(mth*batchsize+batchindex+embedding_length)*60,0],df.iloc[(mth*batchsize+batchindex+embedding_length)*60,1]))\n",
    "        plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "        plt.show()\n",
    "        # plt.savefig(dir + 'Export/' + measure + mth + '.png', bbox_inches='tight')\n",
    "        #resultdf.to_csv(dir + 'Export/' + measure + mth + '.csv')\n",
    "    error=result-truevalue\n",
    "    display(error)\n",
    "\n",
    "        ### Add properties to geojson and export\n",
    "        # Tmaxes = resultdf['Tmax'].tolist()\n",
    "        # for i in range(len(resultdf.index)):\n",
    "        #     basejson['features'][i]['properties']['Tmax'] = Tmaxes[i]\n",
    "        # with open(dir + 'Export/' + measure + mth + '.geojson', 'w') as outfile:\n",
    "        #     json.dump(basejson, outfile)\n",
    "\n",
    "    # avg = sum(scores_mths) / len(scores_mths)\n",
    "    # scores_all.append([k,C,gamma,n] + scores_mths + [avg] )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(clusternum, 1, figsize=(10, 16), sharex=True)\n",
    "for clusterid,ax in enumerate(axes):\n",
    "    sns.boxplot(data = puredata[plotdf['cluster']==clusterid].to_numpy().reshape(-1,24), ax=ax) \n",
    "    ax.set_ylabel(\"\") \n",
    "    ax.set_title(\"Temperature prediction error of stations in cluster {}\".format(clusterid)) \n",
    "    if ax != axes[-1]: \n",
    "        ax.set_xlabel('')\n",
    "    else:\n",
    "        ax.set_xlabel(\"time in the day\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the training results\n",
    "'''\n",
    "for targetstationid in range(14):\n",
    "    mymodel = gru(embedding_length=embedding_length,hidden_size=64,output_size=13,batch_size=batchsize)\n",
    "    with open('trainednw\\\\{}grumodel_target{}.pkl'.format(measure,targetstationid),'wb') as f:\n",
    "        pickle.dump(mymodel,f)\n",
    "    mymodel = MyModel(embedding_length=embedding_length,hidden_size=64,output_size=13,batch_size=batchsize)\n",
    "    with open('trainednw\\\\{}lstmmodel_target{}.pkl'.format(measure,targetstationid),'wb') as f:\n",
    "        pickle.dump(mymodel,f)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
